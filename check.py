# -*- coding: utf-8 -*-
# PDF ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰â†’RAGï¼ˆTF-IDFæ¤œç´¢ï¼‰â†’GPT-4ç³»ã§è©•ä¾¡/èª¤å­—è„±å­—ãƒã‚§ãƒƒã‚¯
# çµæœã¨å¾—ç‚¹ã¯ CSVï¼ˆdata/history.csvï¼‰ã«è¿½è¨˜ã—ã¦ã€[history]ã§é–²è¦§å¯èƒ½

import io
import json
import re
from datetime import datetime

import pandas as pd
import streamlit as st

from common import (
    extract_text_from_pdf,
    chunk_text_for_japanese,
    build_tfidf_index,
    retrieve_top_k,
    load_prompts,
    call_openai_with_context,
    append_history,
    guess_company_name_from_text,
    ensure_data_dirs,
    parse_score_safely
)


def _render_settings_box():
    """ãƒã‚§ãƒƒã‚¯ã®å…±é€šè¨­å®š UIã€‚è¿”ã‚Šå€¤ã¯è¾æ›¸ã€‚"""
    with st.expander("âš™ï¸ é«˜åº¦ãªè¨­å®šï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰", expanded=False):
        top_k = st.slider("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ LLM ã«æ¸¡ã™ãƒãƒ£ãƒ³ã‚¯æ•°ï¼ˆTop-Kï¼‰", 3, 12, 6)
        chunk_chars = st.slider("ãƒãƒ£ãƒ³ã‚¯æœ€å¤§æ–‡å­—æ•°", 500, 2000, 1200, step=100)
        overlap = st.slider("ãƒãƒ£ãƒ³ã‚¯ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æ–‡å­—æ•°", 0, 600, 200, step=50)
        model = st.text_input("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆç©ºæ¬„ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰", value="")
    return {
        "top_k": top_k,
        "chunk_chars": chunk_chars,
        "overlap": overlap,
        "model": model.strip() or None
    }


def _render_result_box(title: str, content: str, parsed_json: dict | None):
    """LLM ã®å‡ºåŠ›ã‚’è¡¨ç¤ºã€‚JSONã«è¦‹ãˆã‚Œã°å±•é–‹ã€ç„¡ç†ãªã‚‰åŸæ–‡è¡¨ç¤ºã€‚"""
    st.subheader(title)
    col1, col2 = st.columns([2, 1])

    with col1:
        if parsed_json:
            st.success("æ§‹é€ åŒ–å‡ºåŠ›ï¼ˆJSONï¼‰ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
            st.json(parsed_json)
        else:
            st.info("æ§‹é€ åŒ–ï¼ˆJSONï¼‰ã§å—ã‘å–ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚åŸæ–‡ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
            st.write(content)

    with col2:
        # ã‚¹ã‚³ã‚¢æŠ½å‡ºã®è©¦è¡Œï¼ˆå¯©æŸ»é …ç›®ãƒ¢ãƒ¼ãƒ‰ã‚’æƒ³å®šï¼‰
        score = parse_score_safely(parsed_json or content)
        st.metric("æŠ½å‡ºã‚¹ã‚³ã‚¢ï¼ˆæ¨å®šï¼‰", value="-" if score is None else f"{score} ç‚¹")
        return score


def render():
    """ãƒã‚§ãƒƒã‚¯ç”»é¢ã®æç”»ï¼ˆåˆæœŸè¡¨ç¤ºãƒšãƒ¼ã‚¸ï¼‰"""
    ensure_data_dirs()
    st.title("âœ… äº‹æ¥­è¨ˆç”»æ›¸ãƒã‚§ãƒƒã‚¯")

    # ãƒã‚§ãƒƒã‚¯ç¨®åˆ¥ã®åˆ‡æ›¿ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã¯ãªãã€ç”»é¢å†…ã§åˆ‡æ›¿ï¼‰
    mode = st.radio(
        "ãƒã‚§ãƒƒã‚¯ç¨®åˆ¥",
        options=["criteria", "typo"],
        format_func=lambda x: "å¯©æŸ»é …ç›®ãƒã‚§ãƒƒã‚¯" if x == "criteria" else "èª¤å­—è„±å­—ãƒ»æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯",
        horizontal=True
    )

    # PDF ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€
    uploaded = st.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ10ã€œ20ãƒšãƒ¼ã‚¸æƒ³å®šï¼‰", type=["pdf"])

    # ä¼æ¥­åï¼ˆPDF ã‹ã‚‰æ¨å®š or æ‰‹å…¥åŠ›ï¼‰
    company_name = st.text_input("ä¼æ¥­åï¼ˆç©ºæ¬„ãªã‚‰PDFã‹ã‚‰è‡ªå‹•æ¨å®šã‚’è©¦è¡Œï¼‰", value="")

    # è¨­å®š
    settings = _render_settings_box()

    # å®Ÿè¡Œãƒœã‚¿ãƒ³
    run = st.button("ğŸš€ ã“ã®å†…å®¹ã§ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ", use_container_width=True, type="primary")

    if not run:
        st.caption("â€» PDF ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ãƒã‚§ãƒƒã‚¯ãŒå§‹ã¾ã‚Šã¾ã™ã€‚")
        return

    if not uploaded:
        st.error("PDF ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    # PDF â†’ å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
    with st.spinner("PDF ã‚’è§£æã—ã¦ã„ã¾ã™â€¦"):
        try:
            pdf_bytes = uploaded.read()
            text = extract_text_from_pdf(io.BytesIO(pdf_bytes))
        except Exception as e:
            st.error(f"PDF ã®èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return

    if not text or len(text.strip()) == 0:
        st.error("PDF ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆã‚¹ã‚­ãƒ£ãƒ³PDFã®å¯èƒ½æ€§ï¼‰ã€‚OCRã‚’é€šã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    # ä¼æ¥­åã®æ¨å®š
    if not company_name.strip():
        company_name = guess_company_name_from_text(text) or "ï¼ˆä¼æ¥­åä¸æ˜ï¼‰"
    st.write(f"æ¨å®šä¼æ¥­å: **{company_name}**")

    # ãƒãƒ£ãƒ³ã‚¯åŒ– â†’ TF-IDF ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    with st.spinner("RAG ç”¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ã„ã¾ã™â€¦"):
        chunks = chunk_text_for_japanese(text, max_chars=settings["chunk_chars"], overlap=settings["overlap"])
        vectorizer, matrix = build_tfidf_index(chunks)

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—
    prompts = load_prompts()
    if mode == "criteria":
        task_prompt = prompts["criteria_prompt"]
        title = "å¯©æŸ»é …ç›®ãƒã‚§ãƒƒã‚¯çµæœ"
        system_hint = (
            "ã‚ãªãŸã¯æ—¥æœ¬ã®ä¸­å°ä¼æ¥­å‘ã‘è£œåŠ©é‡‘ï¼ˆä¾‹ï¼šã‚‚ã®ã¥ãã‚Šè£œåŠ©é‡‘ï¼‰ã®å¯©æŸ»å“¡AIã§ã™ã€‚"
            "ä¸ãˆã‚‰ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç”³è«‹æ›¸æŠœç²‹ï¼‰ã«åŸºã¥ãã€è©•ä¾¡åŸºæº–ã«æ²¿ã£ã¦å³æ ¼ã«åˆ¤å®šã—ã¾ã™ã€‚"
            "å‡ºåŠ›ã¯ã§ãã‚‹é™ã‚Š JSON å½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚"
        )
    else:
        task_prompt = prompts["typo_prompt"]
        title = "èª¤å­—è„±å­—ãƒ»æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯çµæœ"
        system_hint = (
            "ã‚ãªãŸã¯æ—¥æœ¬èªæ–‡æ›¸ã®æ ¡æ­£AIã§ã™ã€‚èª¤å­—è„±å­—ã€è¡¨è¨˜ã‚†ã‚Œã€æ•°å€¤ãƒ»å˜ä½ã®ä¸æ•´åˆã€ç¤¾åãƒ»äººåã®ä¸ä¸€è‡´ã€"
            "æ—¥ä»˜ã®çŸ›ç›¾ãªã©ã‚’ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç”³è«‹æ›¸æŠœç²‹ï¼‰ã«åŸºã¥ã„ã¦æ¤œå‡ºã—ã€ææ¡ˆã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"
            "å‡ºåŠ›ã¯å¯èƒ½ãªã‚‰ JSON å½¢å¼ã«ã—ã¦ãã ã•ã„ã€‚"
        )

    # RAGï¼šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ã‚¯ã‚¨ãƒªã‚’ä½œã‚Šã€é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢
    with st.spinner("é–¢é€£ã™ã‚‹è¨˜è¿°ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™â€¦"):
        # ã‚·ãƒ³ãƒ—ãƒ«ã«ã€Œã‚¿ã‚¹ã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†’é ­300å­—ã€ã‚’ã‚¯ã‚¨ãƒªã¨ã—ã¦ä½¿ç”¨ï¼ˆå®Ÿéœ€ãªã‚‰è¦³ç‚¹ã”ã¨ã«è¤‡æ•°ã‚¯ã‚¨ãƒªæ¨å¥¨ï¼‰
        query = task_prompt[:300]
        top_chunks_idx, top_chunks = retrieve_top_k(query, vectorizer, matrix, chunks, k=settings["top_k"])

    # LLM å‘¼ã³å‡ºã—
    with st.spinner("LLMï¼ˆGPT-4ç³»ï¼‰ã§è©•ä¾¡ã—ã¦ã„ã¾ã™â€¦"):
        llm_text = call_openai_with_context(
            system_prompt=system_hint,
            user_task_prompt=task_prompt,
            context_chunks=top_chunks,
            model_override=settings["model"]
        )

    # å‡ºåŠ›ã®è¡¨ç¤º
    parsed_json = None
    if llm_text:
        try:
            parsed_json = json.loads(llm_text)
        except Exception:
            parsed_json = None

    score = _render_result_box(title, llm_text or "(å‡ºåŠ›ãªã—)", parsed_json)

    # å‚ç…§ã—ãŸæŠœç²‹ï¼ˆäººé–“ã®æ ¹æ‹ ç¢ºèªç”¨ï¼‰
    with st.expander("ğŸ” LLM ã«æ¸¡ã—ãŸå‚ç…§æŠœç²‹ï¼ˆTop-Kï¼‰", expanded=False):
        for i, (idx, ch) in enumerate(zip(top_chunks_idx, top_chunks), start=1):
            st.markdown(f"**[{i}] ãƒãƒ£ãƒ³ã‚¯ #{idx}**")
            st.write(ch)

    # å±¥æ­´ CSV ã¸ã®ä¿å­˜
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    append_history(
        timestamp=timestamp,
        company_name=company_name,
        score=score if score is not None else "",
        mode="å¯©æŸ»é …ç›®" if mode == "criteria" else "èª¤å­—è„±å­—",
        filename=getattr(uploaded, "name", "uploaded.pdf")
    )

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼ˆJSON/Markdownï¼‰
    colA, colB = st.columns(2)
    with colA:
        st.download_button(
            "ğŸ“¥ è§£æçµæœï¼ˆJSON or åŸæ–‡ï¼‰ã‚’ä¿å­˜",
            data=(json.dumps(parsed_json, ensure_ascii=False, indent=2) if parsed_json else (llm_text or "")),
            file_name=f"analysis_{mode}_{timestamp.replace(' ','_')}.{'json' if parsed_json else 'txt'}",
            mime="application/json" if parsed_json else "text/plain"
        )
    with colB:
        st.success("å±¥æ­´ã«è¨˜éŒ²ã—ã¾ã—ãŸã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ğŸ“œ å±¥æ­´ã‹ã‚‰ä¸€è¦§è¡¨ç¤ºã§ãã¾ã™ã€‚")
